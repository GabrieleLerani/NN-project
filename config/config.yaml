net:
  data_dim: 1
  in_channels: 1
  out_channels: 10
  hidden_channels: 140
  no_blocks: 4
  bias: False
  block_type: "s4"

kernel:
  kernel_no_layers: 4
  kernel_hidden_channels: 32
  kernel_size: 33
  conv_type: "conv"
  fft_threshold: 50
  omega_0: 20

load_model:
  pre_trained: True
  model: "last"


train:
  logger: True
  callbacks: True
  profiler: True
  accelerator: "cpu"
  devices: "auto"
  warmup_epochs: 10
  epochs: 210
  learning_rate: 0.01
  batch_size: 10
  start_factor: 1e-6
  end_factor: 1.0
  loss_fn: "cross_entropy"
  optimizer: "AdamW"
  dropout_rate: 10
  weight_decay: 1e-4
  max_epoch_no_improvement: 200

test:
  epochs : 20
  batch_size : 10

data:
  data_dir : "datasets"
  dataset : "sc_mfcc"
  type: "default"
  reduced_dataset: False
  # this line is used only in datamodules that uses LRA as dataset (pathfinder, listops, etc.)
  light_lra: False

# Comment the two sections below to make hydra generate the files again
defaults:  
  - _self_  
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .